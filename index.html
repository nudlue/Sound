<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <title>ì˜¤ë””ì˜¤ ë¶„ë¥˜ ë°ëª¨ (ë…¹ìŒ â†’ ì¢…ë£Œ â†’ ë¶„ì„)</title>

  <!-- TFJS + Speech Commands -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.6.0/dist/speech-commands.min.js"></script>

  <style>
    body { font-family: "Noto Sans KR", Arial, sans-serif; margin: 36px; }
    h1 { display:flex; align-items:center; gap:10px; }
    button { padding:10px 18px; font-size:16px; margin-right:8px; }
    #status { margin-top:18px; font-weight:700; }
    table { margin-top:14px; border-collapse:collapse; width:360px; }
    th, td { border:1px solid #ccc; padding:8px 12px; text-align:left; }
    .hidden { display:none; }
  </style>
</head>
<body>
  <h1>ğŸ”Š ì˜¤ë””ì˜¤ ë¶„ë¥˜ ë°ëª¨</h1>

  <div>
    <button id="btnStart">ë…¹ìŒ ì‹œì‘</button>
    <button id="btnStop" disabled>ë…¹ìŒ ì¢…ë£Œ</button>
  </div>

  <p id="status">ìƒíƒœ: ëŒ€ê¸° ì¤‘</p>

  <table id="resultTable" class="hidden">
    <thead>
      <tr><th>í´ë˜ìŠ¤</th><th>í™•ë¥  (%)</th></tr>
    </thead>
    <tbody></tbody>
  </table>

  <script>
  // ====== ì„¤ì •: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ê°™ì€ í´ë”ì— ì˜¬ë ¤ë‘” ìƒíƒœ) ======
  const MODEL_URL = "./model.json";
  const METADATA_URL = "./metadata.json";

  // ì „ì—­ ë³€ìˆ˜
  let recognizer = null;
  let audioChunks = [];
  let mediaRecorder = null;
  let isRecording = false;

  // ë²„íŠ¼
  const btnStart = document.getElementById("btnStart");
  const btnStop = document.getElementById("btnStop");
  const statusEl = document.getElementById("status");
  const resultTable = document.getElementById("resultTable");
  const resultTbody = resultTable.querySelector("tbody");

  // ëª¨ë¸ ë¡œë“œ (speech-commands, BROWSER_FFT)
  async function loadModel() {
    statusEl.innerText = "ìƒíƒœ: ëª¨ë¸ ë¡œë“œ ì¤‘...";
    try {
      recognizer = await speechCommands.create(
        "BROWSER_FFT",
        undefined,
        MODEL_URL,
        METADATA_URL
      );
      await recognizer.ensureModelLoaded();
      statusEl.innerText = "ìƒíƒœ: ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. ë…¹ìŒ ì‹œì‘ ê°€ëŠ¥";
      console.log("ëª¨ë¸ ë¼ë²¨:", recognizer.wordLabels());
    } catch (err) {
      console.error("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", err);
      statusEl.innerText = "ìƒíƒœ: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨(ì½˜ì†” í™•ì¸)";
    }
  }
  loadModel();

  // ë…¹ìŒ ì‹œì‘
  btnStart.addEventListener("click", async () => {
    if (isRecording) return;
    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ë° MediaRecorder ì‹œì‘
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      audioChunks = [];

      mediaRecorder.ondataavailable = e => {
        if (e.data && e.data.size > 0) audioChunks.push(e.data);
      };

      mediaRecorder.onstart = () => {
        isRecording = true;
        btnStart.disabled = true;
        btnStop.disabled = false;
        statusEl.innerText = "ìƒíƒœ: ğŸ™ ë…¹ìŒ ì¤‘...";
      };

      mediaRecorder.start();
    } catch (err) {
      console.error("ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:", err);
      statusEl.innerText = "ìƒíƒœ: ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨(ê¶Œí•œ í—ˆìš© í•„ìš”)";
    }
  });

  // ë…¹ìŒ ì¢…ë£Œ & ì²˜ë¦¬
  btnStop.addEventListener("click", async () => {
    if (!isRecording) return;
    mediaRecorder.stop();

    mediaRecorder.onstop = async () => {
      isRecording = false;
      btnStart.disabled = false;
      btnStop.disabled = true;
      statusEl.innerText = "ìƒíƒœ: ë…¹ìŒ ì¢…ë£Œ â€” ì²˜ë¦¬ ì¤‘...";

      // Blob -> ArrayBuffer -> AudioBuffer
      const blob = new Blob(audioChunks, { type: "audio/webm" }); // ë¸Œë¼ìš°ì €ì— ë”°ë¼ webm/wav
      const arrayBuffer = await blob.arrayBuffer();

      try {
        const audioCtx = new (window.OfflineAudioContext || window.AudioContext)();
        const decoded = await audioCtx.decodeAudioData(arrayBuffer.slice(0));
        // ëª¨ë¸ í˜¸í™˜ ìƒ˜í”Œë ˆì´íŠ¸ (ì¼ë°˜ì ìœ¼ë¡œ 44100). speech-commandsê°€ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ ê°€ëŠ¥í•˜ì§€ë§Œ
        // ì•ˆì •ì„±ì„ ìœ„í•´ ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í‘œì¤€ ìƒ˜í”Œë ˆì´íŠ¸(44100)ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§ ìˆ˜í–‰
        const targetRate = 44100;
        const resampled = await resampleAudioBuffer(decoded, targetRate);
        const floatData = getMonoFloat32(resampled);

        // ëª¨ë¸ì— ë„£ì–´ ì˜ˆì¸¡
        await classifyFloat32(floatData);
      } catch (err) {
        console.error("ì˜¤ë””ì˜¤ ë””ì½”ë”©/ì²˜ë¦¬ ì˜¤ë¥˜:", err);
        statusEl.innerText = "ìƒíƒœ: ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨(ì½˜ì†” í™•ì¸)";
      }
    };
  });

  // ===== í—¬í¼: AudioBufferë¥¼ target sampleRateë¡œ ë¦¬ìƒ˜í”Œë§ =====
  async function resampleAudioBuffer(audioBuffer, targetSampleRate) {
    if (audioBuffer.sampleRate === targetSampleRate) return audioBuffer;

    const channels = audioBuffer.numberOfChannels;
    const duration = audioBuffer.duration;
    const length = Math.ceil(duration * targetSampleRate);

    // OfflineAudioContextë¥¼ ì´ìš©í•œ ë¦¬ìƒ˜í”Œë§
    const offlineCtx = new OfflineAudioContext(channels, length, targetSampleRate);
    const bufferSource = offlineCtx.createBufferSource();
    bufferSource.buffer = audioBuffer;
    bufferSource.connect(offlineCtx.destination);
    bufferSource.start(0);

    const rendered = await offlineCtx.startRendering();
    return rendered;
  }

  // ===== í—¬í¼: AudioBuffer -> ëª¨ë…¸ Float32Array (ì±„ë„ í‰ê· ) =====
  function getMonoFloat32(audioBuffer) {
    const ch = audioBuffer.numberOfChannels;
    const l = audioBuffer.length;
    const result = new Float32Array(l);
    // average channels
    if (ch === 1) {
      result.set(audioBuffer.getChannelData(0));
    } else {
      for (let i = 0; i < l; i++) {
        let sum = 0;
        for (let c = 0; c < ch; c++) sum += audioBuffer.getChannelData(c)[i];
        result[i] = sum / ch;
      }
    }
    return result;
  }

  // ===== ëª¨ë¸ì— Float32Array ë„£ê³  ì˜ˆì¸¡ ë°›ê¸° =====
  async function classifyFloat32(float32Audio) {
    if (!recognizer) {
      console.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ");
      statusEl.innerText = "ìƒíƒœ: ëª¨ë¸ ë¡œë“œ ëŒ€ê¸° ì¤‘...";
      return;
    }

    try {
      // speech-commands recognizerì˜ recognize í•¨ìˆ˜ëŠ”
      // raw audio Float32Arrayë¥¼ ë°›ì•„ ë‚´ë¶€ì—ì„œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì²˜ë¦¬ë¥¼ í•´ì¤Œ.
      // (BROWSER_FFT ì˜µì…˜ ì‚¬ìš© ì‹œ)
      const result = await recognizer.recognize(float32Audio);

      // result: {scores: Float32Array, spectrogram: {...}, ...}
      if (!result || !result.scores) {
        console.warn("ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ:", result);
        statusEl.innerText = "ìƒíƒœ: ì˜ˆì¸¡ ì‹¤íŒ¨(ê²°ê³¼ ì—†ìŒ)";
        return;
      }

      // ê²°ê³¼ ì¶œë ¥
      updateResultTable(result.scores, recognizer.wordLabels());
      statusEl.innerText = "ìƒíƒœ: ì™„ë£Œ";
    } catch (err) {
      console.error("ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜:", err);
      statusEl.innerText = "ìƒíƒœ: ì˜ˆì¸¡ ì‹¤íŒ¨(ì½˜ì†” í™•ì¸)";
    }
  }

  // ===== ê²°ê³¼ í…Œì´ë¸” ê°±ì‹  =====
  function updateResultTable(scores, labels) {
    resultTbody.innerHTML = "";
    // scoresëŠ” Float32Arrayê°™ì€ ë°°ì—´
    const arr = Array.from(scores);
    // ë§¤í•‘: label & score
    for (let i = 0; i < arr.length; i++) {
      const tr = document.createElement("tr");
      const tdLabel = document.createElement("td");
      tdLabel.textContent = labels[i] ?? `class ${i}`;
      const tdScore = document.createElement("td");
      tdScore.textContent = (arr[i] * 100).toFixed(2) + "%";
      tr.appendChild(tdLabel);
      tr.appendChild(tdScore);
      resultTbody.appendChild(tr);
    }
    resultTable.classList.remove("hidden");
  }

  // ========== ìœ ìš©í•œ ë””ë²„ê·¸: model metadata ë³´ê¸° ==========
  // (ëª¨ë¸ ë¡œë“œ í›„ ë¼ë²¨ í™•ì¸ ë“±)
  window.getModelInfo = function() {
    if (!recognizer) { console.log("ëª¨ë¸ ì—†ìŒ"); return; }
    console.log("labels:", recognizer.wordLabels());
    // spectrogram info (if available)
    if (recognizer.params) console.log("recognizer.params:", recognizer.params);
  };

  </script>
</body>
</html>
